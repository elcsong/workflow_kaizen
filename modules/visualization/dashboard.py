"""
ETL ë°ì´í„° ëŒ€ì‹œë³´ë“œ
Workflow Kaizen ETL ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ì—¬ ë³´ì—¬ì£¼ëŠ” Streamlit ëŒ€ì‹œë³´ë“œ

ì‹¤í–‰ ë°©ë²•:
    streamlit run modules/visualization/dashboard.py
"""

import streamlit as st
import pandas as pd
import json
import os
import io
from pathlib import Path
from typing import Dict, List, Any, Optional
import plotly.express as px
import plotly.graph_objects as go

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Workflow Kaizen - ETL ë°ì´í„° ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ§ª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
DATA_DIR = Path(__file__).parent.parent.parent / "data"
REACH_DATA_FILE = DATA_DIR / "reach_data.json"
KOSHA_DATA_FILE = DATA_DIR / "kosha_data.json"

def load_reach_data() -> Dict[str, Any]:
    """EU REACH ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
        if not REACH_DATA_FILE.exists():
            st.error(f"REACH ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {REACH_DATA_FILE}")
            st.info("ğŸ’¡ EU REACH ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
            st.code("python modules/etl-pipeline/reach_etl.py --skip-download")
            return {}

        # íŒŒì¼ í¬ê¸° í™•ì¸ (ë„ˆë¬´ ì‘ì€ íŒŒì¼ì€ ì˜¤ë¥˜)
        file_size = REACH_DATA_FILE.stat().st_size
        if file_size < 10:  # 10ë°”ì´íŠ¸ ë¯¸ë§Œì€ ë¹„ì •ìƒ
            st.error(f"REACH ë°ì´í„° íŒŒì¼ì´ ë„ˆë¬´ ì‘ê±°ë‚˜ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤: {file_size} bytes")
            st.info("ğŸ’¡ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ìƒì„±í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
            st.code("python modules/etl-pipeline/reach_etl.py --skip-download")
            return {}

        with open(REACH_DATA_FILE, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            if not content:
                st.error("REACH ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return {}

            data = json.loads(content)

            # ë°ì´í„° êµ¬ì¡° ê²€ì¦
            if not isinstance(data, dict):
                st.error("REACH ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ (dict íƒ€ì…ì´ ì•„ë‹˜).")
                return {}

            # í•„ìˆ˜ í‚¤ í™•ì¸
            expected_keys = ['svhc', 'annex_xiv', 'annex_xvii']
            found_keys = [key for key in expected_keys if key in data]
            if not found_keys:
                st.error("REACH ë°ì´í„°ì— í•„ìš”í•œ ì¹´í…Œê³ ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {}

            st.success(f"âœ… REACH ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(found_keys)}ê°œ ì¹´í…Œê³ ë¦¬")
            return data

    except json.JSONDecodeError as e:
        st.error(f"REACH ë°ì´í„° JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        st.info("ğŸ’¡ íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì¬ìƒì„±í•˜ì„¸ìš”:")
        st.code("python modules/etl-pipeline/reach_etl.py --skip-download")
        return {}
    except UnicodeDecodeError as e:
        st.error(f"REACH ë°ì´í„° íŒŒì¼ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
        st.info("ğŸ’¡ UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ì„ ë‹¤ì‹œ ìƒì„±í•˜ì„¸ìš”.")
        return {}
    except Exception as e:
        st.error(f"REACH ë°ì´í„° ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

def load_kosha_data() -> Dict[str, Any]:
    """í•œêµ­ KOSHA ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not KOSHA_DATA_FILE.exists():
            st.warning("ğŸ‡°ğŸ‡· KOSHA ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ í˜„ì¬ í•œêµ­ ì‚°ì•ˆë²• ë°ì´í„°ëŠ” ìƒ˜í”Œ ë°ì´í„° ê¸°ë°˜ì…ë‹ˆë‹¤.")
            st.info("ğŸ’¡ ë²•ë ¹ì •ë³´ì‹œìŠ¤í…œ ë³µêµ¬ í›„ ì‹¤ì œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ì˜ˆì •ì…ë‹ˆë‹¤.")
            st.code("# í–¥í›„ ì‚¬ìš© ì˜ˆì •\npython modules/etl-pipeline/kosha_etl.py --data-type special_materials")
            return {}

        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = KOSHA_DATA_FILE.stat().st_size
        if file_size < 10:  # 10ë°”ì´íŠ¸ ë¯¸ë§Œì€ ë¹„ì •ìƒ
            st.error(f"KOSHA ë°ì´í„° íŒŒì¼ì´ ë„ˆë¬´ ì‘ê±°ë‚˜ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤: {file_size} bytes")
            return {}

        with open(KOSHA_DATA_FILE, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            if not content:
                st.error("KOSHA ë°ì´í„° íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return {}

            data = json.loads(content)

            # ë°ì´í„° êµ¬ì¡° ê²€ì¦
            if not isinstance(data, dict):
                st.error("KOSHA ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ (dict íƒ€ì…ì´ ì•„ë‹˜).")
                return {}

            # ë©”íƒ€ë°ì´í„° í™•ì¸
            if 'metadata' not in data:
                st.error("KOSHA ë°ì´í„°ì— ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {}

            st.success("âœ… KOSHA ë°ì´í„° ë¡œë“œ ì™„ë£Œ (ìƒ˜í”Œ ë°ì´í„°)")
            return data

    except json.JSONDecodeError as e:
        st.error(f"KOSHA ë°ì´í„° JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return {}
    except UnicodeDecodeError as e:
        st.error(f"KOSHA ë°ì´í„° íŒŒì¼ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
        return {}
    except Exception as e:
        st.error(f"KOSHA ë°ì´í„° ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}

def flatten_reach_data(reach_data: Dict[str, Any]) -> pd.DataFrame:
    """REACH ë°ì´í„°ë¥¼ í‰íƒ„í™”í•˜ì—¬ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    all_data = []

    for category, category_data in reach_data.items():
        if category == "metadata":
            continue

        metadata = category_data.get("metadata", {})
        data_list = category_data.get("data", [])

        for item in data_list:
            item_copy = item.copy()
            item_copy["category"] = category
            item_copy["category_description"] = metadata.get("annex_type", category)
            all_data.append(item_copy)

    if not all_data:
        return pd.DataFrame()

    df = pd.DataFrame(all_data)
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    df.columns = df.columns.str.replace('_', ' ').str.title()
    return df

def process_kosha_data(kosha_data: Dict[str, Any]) -> pd.DataFrame:
    """KOSHA ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    metadata = kosha_data.get("metadata", {})
    data_list = kosha_data.get("data", [])

    if not data_list:
        return pd.DataFrame()

    df = pd.DataFrame(data_list)
    # ì»¬ëŸ¼ëª… ì •ë¦¬ (í•œê¸€ ìœ ì§€)
    df.columns = df.columns.str.replace('_', ' ')
    return df

def display_data_summary(df: pd.DataFrame, title: str):
    """ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    if df.empty:
        st.warning("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.subheader(f"ğŸ“Š {title} ìš”ì•½")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("ì´ í•­ëª© ìˆ˜", len(df))

    with col2:
        # ë¬¼ì§ˆëª…ì„ ë‚˜íƒ€ë‚´ëŠ” ì»¬ëŸ¼ ì°¾ê¸°
        substance_series = df.get('Substance Name') or df.get('ë¬¼ì§ˆëª…') or (df.iloc[:, 0] if len(df.columns) > 0 else None)
        unique_count = substance_series.nunique() if substance_series is not None and len(df) > 0 else 0
        st.metric("ê³ ìœ  ë¬¼ì§ˆ ìˆ˜", unique_count)

    with col3:
        cas_col = None
        for col in ['Cas No', 'CAS_No', 'Cas-No']:
            if col in df.columns:
                cas_col = col
                break
        if cas_col:
            valid_cas = df[cas_col].notna() & (df[cas_col] != '') & (df[cas_col] != '-')
            st.metric("CAS ë²ˆí˜¸ ë³´ìœ ", valid_cas.sum())
        else:
            st.metric("CAS ë²ˆí˜¸ ë³´ìœ ", "N/A")

    with col4:
        if 'Date Of Inclusion' in df.columns:
            try:
                df_copy = df.copy()
                df_copy['Date Of Inclusion'] = pd.to_datetime(df_copy['Date Of Inclusion'], errors='coerce')
                latest_date = df_copy['Date Of Inclusion'].max()
                if pd.notna(latest_date):
                    st.metric("ìµœì‹  ë“±ë¡ì¼", latest_date.strftime('%Y-%m-%d'))
                else:
                    st.metric("ìµœì‹  ë“±ë¡ì¼", "N/A")
            except:
                st.metric("ìµœì‹  ë“±ë¡ì¼", "N/A")
        else:
            st.metric("ìµœì‹  ë“±ë¡ì¼", "N/A")

def create_search_filter(df: pd.DataFrame) -> pd.DataFrame:
    """ê²€ìƒ‰ ë° í•„í„°ë§ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤."""
    st.subheader("ğŸ” ê²€ìƒ‰ ë° í•„í„°ë§")

    col1, col2 = st.columns([2, 1])

    with col1:
        search_term = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", placeholder="ë¬¼ì§ˆëª…, CAS ë²ˆí˜¸ ë“±ìœ¼ë¡œ ê²€ìƒ‰")

    with col2:
        # ë™ì  í•„í„°ë§ ì˜µì…˜
        filter_options = ["ì „ì²´"] + list(df.columns)
        selected_filter = st.selectbox("í•„í„°ë§í•  ì»¬ëŸ¼ ì„ íƒ", filter_options)

    # ê²€ìƒ‰ ì ìš©
    if search_term:
        mask = df.astype(str).apply(lambda x: x.str.contains(search_term, case=False, na=False)).any(axis=1)
        df_filtered = df[mask]
        st.info(f"ê²€ìƒ‰ ê²°ê³¼: {len(df_filtered)} ê°œ í•­ëª© (ì „ì²´ {len(df)} ê°œ ì¤‘)")
    else:
        df_filtered = df

    # ì¶”ê°€ í•„í„°ë§
    if selected_filter != "ì „ì²´" and selected_filter in df.columns:
        unique_values = df_filtered[selected_filter].dropna().unique()
        if len(unique_values) > 0:
            selected_values = st.multiselect(
                f"{selected_filter} í•„í„°",
                options=sorted(unique_values),
                default=[]
            )
            if selected_values:
                df_filtered = df_filtered[df_filtered[selected_filter].isin(selected_values)]

    return df_filtered

def display_data_table(df: pd.DataFrame, title: str):
    """ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.subheader(f"ğŸ“‹ {title} ë°ì´í„° í…Œì´ë¸”")

    # í…Œì´ë¸” ì„¤ì •
    st.dataframe(
        df,
        use_container_width=True,
        hide_index=True,
        column_config={
            col: st.column_config.TextColumn(col, width="medium") for col in df.columns
        }
    )

    # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ"):
            csv_data = df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=csv_data,
                file_name=f"{title.lower().replace(' ', '_')}_data.csv",
                mime="text/csv"
            )

    with col2:
        if st.button("ğŸ“¥ Excel ë‹¤ìš´ë¡œë“œ"):
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='Data', index=False)
            buffer.seek(0)
            st.download_button(
                label="Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=buffer,
                file_name=f"{title.lower().replace(' ', '_')}_data.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

def create_visualizations(df: pd.DataFrame, data_type: str):
    """ë°ì´í„° ì‹œê°í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if df.empty:
        return

    st.subheader("ğŸ“ˆ ë°ì´í„° ì‹œê°í™”")

    if data_type == "REACH":
        # REACH ë°ì´í„° ì‹œê°í™”
        if 'Category' in df.columns:
            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
            category_counts = df['Category'].value_counts()
            fig = px.pie(
                values=category_counts.values,
                names=category_counts.index,
                title="REACH ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬"
            )
            st.plotly_chart(fig, use_container_width=True)

        if 'Reason For Inclusion' in df.columns:
            # í¬í•¨ ì´ìœ ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ)
            reason_counts = df['Reason For Inclusion'].value_counts().head(10)
            fig = px.bar(
                x=reason_counts.values,
                y=reason_counts.index,
                orientation='h',
                title="í¬í•¨ ì´ìœ ë³„ ë¶„í¬ (ìƒìœ„ 10ê°œ)"
            )
            st.plotly_chart(fig, use_container_width=True)

    elif data_type == "KOSHA":
        # KOSHA ë°ì´í„° ì‹œê°í™”
        if 'ë¹„ê³ ' in df.columns:
            # ë¹„ê³ ë³„ ë¶„í¬
            remark_counts = df['ë¹„ê³ '].value_counts()
            fig = px.bar(
                x=remark_counts.values,
                y=remark_counts.index,
                orientation='h',
                title="ë¬¼ì§ˆ íŠ¹ì„±ë³„ ë¶„í¬"
            )
            st.plotly_chart(fig, use_container_width=True)

def main():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ í•¨ìˆ˜"""
    st.title("ğŸ§ª Workflow Kaizen - ETL ë°ì´í„° ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")

    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ğŸ›ï¸ ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ")

    data_source = st.sidebar.radio(
        "ë¶„ì„í•  ë°ì´í„° ì„ íƒ",
        ["EU REACH ë°ì´í„°", "í•œêµ­ KOSHA ë°ì´í„°"],
        help="ETLë¡œ ìˆ˜ì§‘ëœ í™”í•™ë¬¼ì§ˆ ë°ì´í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”"
    )

    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ“‹ ì‚¬ìš© ë°©ë²•")
    st.sidebar.markdown("""
    1. **ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ**: ë¶„ì„í•  ë°ì´í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”
    2. **ìš”ì•½ ì •ë³´ í™•ì¸**: ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ë¥¼ í™•ì¸í•˜ì„¸ìš”
    3. **ê²€ìƒ‰ ë° í•„í„°ë§**: ì›í•˜ëŠ” ì¡°ê±´ìœ¼ë¡œ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ì„¸ìš”
    4. **í…Œì´ë¸” í™•ì¸**: ìƒì„¸ ë°ì´í„°ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ í™•ì¸í•˜ì„¸ìš”
    5. **ì‹œê°í™”**: ë°ì´í„° ë¶„í¬ë¥¼ ì°¨íŠ¸ë¡œ í™•ì¸í•˜ì„¸ìš”
    6. **ë‚´ë³´ë‚´ê¸°**: í•„ìš”í•œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”
    """)

    # ë°ì´í„° ë¡œë“œ
    if data_source == "EU REACH ë°ì´í„°":
        st.header("ğŸ‡ªğŸ‡º EU REACH í™”í•™ë¬¼ì§ˆ ë°ì´í„°")
        reach_data = load_reach_data()

        if not reach_data:
            st.error("REACH ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë°ì´í„° í‰íƒ„í™”
        df = flatten_reach_data(reach_data)

        if df.empty:
            st.warning("í‘œì‹œí•  REACH ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìš”ì•½ ì •ë³´ í‘œì‹œ
        display_data_summary(df, "EU REACH")

        # ê²€ìƒ‰ ë° í•„í„°ë§
        df_filtered = create_search_filter(df)

        # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
        display_data_table(df_filtered, "EU REACH")

        # ì‹œê°í™”
        create_visualizations(df_filtered, "REACH")

    else:  # í•œêµ­ KOSHA ë°ì´í„°
        st.header("ğŸ‡°ğŸ‡· í•œêµ­ KOSHA íŠ¹ìˆ˜ê´€ë¦¬ë¬¼ì§ˆ ë°ì´í„°")
        kosha_data = load_kosha_data()

        if not kosha_data:
            st.error("KOSHA ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë°ì´í„° ì²˜ë¦¬
        df = process_kosha_data(kosha_data)

        if df.empty:
            st.warning("í‘œì‹œí•  KOSHA ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìš”ì•½ ì •ë³´ í‘œì‹œ
        display_data_summary(df, "í•œêµ­ KOSHA")

        # ê²€ìƒ‰ ë° í•„í„°ë§
        df_filtered = create_search_filter(df)

        # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
        display_data_table(df_filtered, "í•œêµ­ KOSHA")

        # ì‹œê°í™”
        create_visualizations(df_filtered, "KOSHA")

    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>ğŸš€ Workflow Kaizen ETL ëŒ€ì‹œë³´ë“œ | ë°ì´í„° ì¶œì²˜: ê³µê³µ ë°ì´í„°</p>
        <p>ê°œë°œì: @elcsong | <a href='https://github.com/elcsong/workflow_kaizen'>GitHub Repository</a></p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
